{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87633218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import urllib.parse\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import FreqDist\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b410016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/15 14:03:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/15 14:03:47 WARN Utils: Service 'sparkDriver' could not bind on port 9998. Attempting port 9999.\n",
      "22/03/15 14:03:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/15 14:03:48 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 10005. Attempting port 10006.\n",
      "22/03/15 14:03:49 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"test_notebook\")\\\n",
    "    .master(\"spark://host-192-168-2-176-de1:7077\")\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True)\\\n",
    "    .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"100s\")\\\n",
    "    .config(\"spark.driver.port\",9998)\\\n",
    "    .config(\"spark.blockManager.port\",10005)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd9fef14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://host-192-168-2-176-de1:4041\n"
     ]
    }
   ],
   "source": [
    "print(spark_context.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e7f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "      StructField(\"subreddit\",StringType(),True),\n",
    "      StructField(\"body\",StringType(),True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905d1e37-60e6-4d75-a253-08c8df51096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark_session.read.schema(schema).json(\"hdfs://host-192-168-2-176-de1:9000/comments/RC_2011-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac6c0ac-390a-4b93-ac0a-a093e97c1738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#write to parquet ( done only once)\n",
    "#df.write.parquet(\"hdfs://host-192-168-2-176-de1:9000/comments/parquet/reddit.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5cf248-5a00-40d5-9183-0f5e791189ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "parqDF = spark_session.read.parquet(\"hdfs://host-192-168-2-176-de1:9000/comments/parquet/reddit.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14a6299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.limit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa9201-cd68-477b-8194-b495eb96175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.select('subreddit').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d03e0d1-227f-4b0e-8ddb-5247d9497c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the operation takes 49.16558814048767 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "most_popular_categories = df.groupBy('subreddit').count().sort('count', ascending=False).head(50)\n",
    "end = time.time()\n",
    "print(\"the operation takes {0} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a5a8c69-6c94-44f9-9dc3-bfbae4307c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the operation takes 4.818623304367065 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 14:38:41 ERROR TaskSchedulerImpl: Lost executor 1 on 192.168.2.176: Command exited with code 137\n",
      "22/03/15 14:38:41 ERROR TransportRequestHandler: Error sending result RpcResponse[requestId=5012939683213738533,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /192.168.2.176:46188; closing connection\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/03/15 14:46:29 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "22/03/15 14:46:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:919)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:154)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:262)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:169)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "most_popular_categories = parqDF.groupBy('subreddit').count().sort('count', ascending=False).head(50)\n",
    "end = time.time()\n",
    "print(\"the operation takes {0} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b12133-b743-49a6-9ef9-0243f6187ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ed361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "cat_to_id = {}\n",
    "id_to_cat = {}\n",
    "\n",
    "for c in categories:\n",
    "    cat_to_id[c['subreddit']] = i\n",
    "    id_to_cat[i] = c['subreddit']\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00208e31-5c4f-443a-91b9-e3747f209de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_id(cat):\n",
    "    return cat_to_id[cat]\n",
    "\n",
    "transform_to_id_udf = udf(transform_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57e3ce5d-4afc-4b30-a497-cc76c2b2a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"cat_id\",transform_to_id_udf(df[\"subreddit\"]).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a29a88-95c2-40d3-a108-4edbaa11c770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "most_popular_categories = df.groupBy('cat_id').count().sort('count', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "974516cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories_to_keep = []\n",
    "\n",
    "for r in most_popular_categories:\n",
    "    \n",
    "    categories_to_keep.append(r['cat_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfd1c736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:=========================================>              (34 + 2) / 46]\r"
     ]
    }
   ],
   "source": [
    "rdd = df.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "497dae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rdd = rdd.filter(lambda x: x[2] in categories_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea708b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f688e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rdd1 = filtered_rdd.map(lambda x: (x[2], emoji.get_emoji_regexp().sub(u'', x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "285da427",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|http\\S+')\n",
    "filtered_rdd2 = filtered_rdd1.map(lambda x: (x[0], tokenizer.tokenize(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5b7f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rdd3 = filtered_rdd2.map(lambda x: (x[0], [word.lower() for word in x[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be0dc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "all_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "filtered_rdd4 = filtered_rdd3.map(lambda x: (x[0], [word for word in x[1] if not word in all_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40ba0cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "filtered_rdd5 = filtered_rdd4.map(lambda x: (x[0], ([lemmatizer.lemmatize(w) for w in x[1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6482b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SIA()\n",
    "\n",
    "filtered_rdd6 = filtered_rdd5.map(lambda x: (x[0], [sia.polarity_scores(word)['compound'] for word in x[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32416604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_positive_negative(scores):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for s in scores:\n",
    "        if s > 0.1 :\n",
    "            pos += 1\n",
    "        elif s <-0.1:\n",
    "            neg += 1\n",
    "    if pos >= neg:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "find_positive_negative_udf = udf(find_positive_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1b1fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rdd7 = filtered_rdd6.map(lambda x: (x[0], find_positive_negative(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "370a543a-3be8-422e-b8b6-e074d040946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rdd = filtered_rdd7.reduceByKey(lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "704237c2-2c90-4c97-b7be-e9cae5ea5220",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_rdd = final_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42e2055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dic = {}\n",
    "for i in most_popular_categories:\n",
    "    count_dic[i['cat_id']] = i['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c85ccc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f1ee0a4-beda-415b-99e9-5881982a4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reduced_rdd:\n",
    "    final_list.append([id_to_cat[i[0]], float(int(i[1]/count_dic[i[0]]*10000))/100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3af2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10dfdf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame (final_list, columns = ['category', 'frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "517c630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('frequency_table.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd8c5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
