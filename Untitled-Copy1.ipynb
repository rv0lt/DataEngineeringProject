{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fff191-5e16-476b-9dd6-1ee58e0bc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import urllib.parse\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import FreqDist\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc19df87-1c62-4f1b-80ef-49b1739a0d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/15 13:44:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/15 13:44:44 WARN Utils: Service 'sparkDriver' could not bind on port 9998. Attempting port 9999.\n",
      "22/03/15 13:44:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/15 13:44:47 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 10005. Attempting port 10006.\n",
      "22/03/15 13:44:47 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 10006. Attempting port 10007.\n",
      "22/03/15 13:44:47 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"test_notebook\")\\\n",
    "    .master(\"spark://host-192-168-2-176-de1:7077\")\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True)\\\n",
    "    .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"100s\")\\\n",
    "    .config(\"spark.driver.port\",9998)\\\n",
    "    .config(\"spark.blockManager.port\",10005)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694228ad-2d9c-4c9c-805e-eba62bf827da",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "      StructField(\"subreddit\",StringType(),True),\n",
    "      StructField(\"body\",StringType(),True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10344b1-b755-41e6-9e26-fe0784a9721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark_session.read.schema(schema).json(\"hdfs://host-192-168-2-176-de1:9000/comments/RC_2011-07\")\n",
    "#write to parquet ( done only once)\n",
    "#df.write.parquet(\"hdfs://host-192-168-2-176-de1:9000/comments/parquet/reddit.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197d5de-af9c-4de8-854a-4a0fc8097240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "parqDF = spark_session.read.parquet(\"hdfs://host-192-168-2-176-de1:9000/comments/parquet/reddit.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eadad5f-0e38-4780-ad93-1c375d3f9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parqDF = parqDF.limit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f88125-5668-4ace-a9c7-bacbfacf2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "most_popular_categories = parqDF.groupBy('subreddit').count().sort('count', ascending=False).head(50)\n",
    "end = time.time()\n",
    "print(\"the operation takes {0} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5debcb0f-9303-4461-965d-284896111391",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
